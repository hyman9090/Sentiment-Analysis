{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of this exercise is to learn and practice machine learning standard process\n",
    "- Features will be the features choosen in titanic_select_feautres.ipynb\n",
    "- Going to test which classifier is the most powerful one via GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomTreesEmbedding, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve, precision_recall_curve, auc, make_scorer, average_precision_score, roc_auc_score, f1_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data=\n",
    "root = Path(\".\")\n",
    "with zipfile.ZipFile(root/\"titanic.zip\") as z:\n",
    "    names = z.namelist()\n",
    "    df_train = pd.read_csv(z.open(names[2]))\n",
    "    x_df_test = pd.read_csv(z.open(names[1]))\n",
    "    y_df_test = pd.read_csv(z.open(names[0]))\n",
    "    y_df_test = y_df_test.drop(columns=['PassengerId'])\n",
    "    \n",
    "df_test = pd.concat([x_df_test, y_df_test],axis=1)\n",
    "df_data = pd.concat([df_train, df_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the unused variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the variables that varies too much --> not providing much information\n",
    "drop_var = ['PassengerId', \"Name\", \"Ticket\", \"Cabin\"]\n",
    "df_data = df_data.drop(drop_var, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_fill_age = df_data.groupby(\"Sex\")[\"Age\"].mean().to_dict()\n",
    "\n",
    "for gender, fill_age in dict_fill_age.items():\n",
    "    df_data.loc[(df_data.Sex==gender) & (df_data.Age.isna()), \"Age\"] = fill_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.Fare = df_data.Fare.fillna(value=df_data.Fare.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_data.Embarked = SI.fit_transform(df_data[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the categorical variables to numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Sex_encoded\"] = df_data.Sex.map({\"male\": 0, \"female\":1}).astype('int8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_data[\"Embarked_encoded\"] = label_encoder.fit_transform(df_data.Embarked).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different classifiers and find the best set of parameters for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "use_cols = ['Pclass', 'Age', 'Sex_encoded']\n",
    "random_seed = 42\n",
    "\n",
    "est_names = [\n",
    "             'Nearest Neighbours',\n",
    "             'SVM',\n",
    "             'Guassian Process',\n",
    "             'Decision Tree',\n",
    "             'Random Forest',\n",
    "             'Neural Net',\n",
    "             'AdaBoost',\n",
    "             'QDA']\n",
    "\n",
    "est_list = [KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
    "            SVC(gamma=1, C=1, random_state=random_seed, kernel='linear'),\n",
    "            GaussianProcessClassifier(1.0 * RBF(1.0), random_state=random_seed),\n",
    "            DecisionTreeClassifier(max_depth=5, random_state=random_seed),\n",
    "            RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1, random_state=random_seed),\n",
    "            MLPClassifier(alpha=1, max_iter=1000, random_state=random_seed),\n",
    "            AdaBoostClassifier(algorithm=\"SAMME\", random_state=random_seed),\n",
    "            QuadraticDiscriminantAnalysis()\n",
    "            ]\n",
    "\n",
    "est_params = [\n",
    "              {\n",
    "                'est__n_neighbors': [i for i in range(5,26)],\n",
    "                'est__weights': ['uniform', 'distance']\n",
    "                },\n",
    "              {\n",
    "                'est__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                'est__gamma': ['scale', 'auto', 1, 2, 3],\n",
    "                'est__C': [i for i in range(1,11)]\n",
    "                },\n",
    "              {\n",
    "               'est__n_restarts_optimizer': [i for i in range(1,4)],\n",
    "               'est__multi_class': ['one_vs_rest', 'one_vs_one'] \n",
    "                },\n",
    "              {\n",
    "               'est__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "               'est__splitter': ['best', 'random'],\n",
    "               'est__max_depth': [i for i in range(5,11)] \n",
    "                },\n",
    "              {\n",
    "                'est__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                'est__max_depth': [i for i in range(5,11)],\n",
    "                'est__bootstrap': [True, False],\n",
    "                'est__class_weight': ['balanced', 'balanced_subsample']\n",
    "                },\n",
    "              {\n",
    "                'est__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                'est__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'est__learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "                },\n",
    "              {\n",
    "                'est__algorithm': ['SAMME', 'SAMME.R']\n",
    "                },\n",
    "              {\n",
    "                'est__store_covariance': [True, False]\n",
    "                }\n",
    "              ]\n",
    "\n",
    "scoring = {\"recall\":    make_scorer(recall_score, greater_is_better=True),\n",
    "           \"precision\": make_scorer(precision_score, greater_is_better=True),\n",
    "           \"accuracy\":  make_scorer(accuracy_score, greater_is_better=True),\n",
    "           \"F1 score\":  make_scorer(f1_score, greater_is_better=True)\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data.iloc[:df_train.shape[0],:]\n",
    "df_test  = df_data.iloc[df_train.shape[0]:,:]\n",
    "\n",
    "est_grid = []\n",
    "est_best_index = []\n",
    "est_best_score = []\n",
    "est_best_params = []\n",
    "est_best_est = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbours,KNeighborsClassifier(n_neighbors=10, weights='distance'),{'est__n_neighbors': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], 'est__weights': ['uniform', 'distance']}\n",
      "SVM,SVC(C=1, gamma=1, kernel='linear', random_state=42),{'est__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'est__gamma': ['scale', 'auto', 1, 2, 3], 'est__C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
      "Guassian Process,GaussianProcessClassifier(kernel=1**2 * RBF(length_scale=1), random_state=42),{'est__n_restarts_optimizer': [1, 2, 3], 'est__multi_class': ['one_vs_rest', 'one_vs_one']}\n",
      "Decision Tree,DecisionTreeClassifier(max_depth=5, random_state=42),{'est__criterion': ['gini', 'entropy', 'log_loss'], 'est__splitter': ['best', 'random'], 'est__max_depth': [5, 6, 7, 8, 9, 10]}\n",
      "Random Forest,RandomForestClassifier(max_depth=5, max_features=1, random_state=42),{'est__criterion': ['gini', 'entropy', 'log_loss'], 'est__max_depth': [5, 6, 7, 8, 9, 10], 'est__bootstrap': [True, False], 'est__class_weight': ['balanced', 'balanced_subsample']}\n",
      "Neural Net,MLPClassifier(alpha=1, max_iter=1000, random_state=42),{'est__activation': ['identity', 'logistic', 'tanh', 'relu'], 'est__solver': ['lbfgs', 'sgd', 'adam'], 'est__learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
      "AdaBoost,AdaBoostClassifier(algorithm='SAMME', random_state=42),{'est__algorithm': ['SAMME', 'SAMME.R']}\n",
      "QDA,QuadraticDiscriminantAnalysis(),{'est__store_covariance': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, est, params in zip(est_names, est_list, est_params):\n",
    "    pipe = Pipeline( steps= [('scaler', scaler), ('est', est)] )\n",
    "    \n",
    "    grid = GridSearchCV(pipe,\n",
    "                        cv=10,\n",
    "                        param_grid=params,\n",
    "                        scoring= scoring,\n",
    "                        refit='F1 score',\n",
    "                        n_jobs=-1\n",
    "                        )\n",
    "    print(name, est, params, sep=',')\n",
    "    \n",
    "    grid.fit(df_train[use_cols], df_train[\"Survived\"])\n",
    "    \n",
    "    est_grid.append(grid)\n",
    "    est_best_index.append(grid.best_index_)\n",
    "    est_best_score.append(grid.best_score_)\n",
    "    est_best_params.append(grid.best_params_)\n",
    "    est_best_est.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'est__n_neighbors': 11, 'est__weights': 'distance'},\n",
       " {'est__C': 1, 'est__gamma': 'scale', 'est__kernel': 'poly'},\n",
       " {'est__multi_class': 'one_vs_rest', 'est__n_restarts_optimizer': 1},\n",
       " {'est__criterion': 'gini', 'est__max_depth': 10, 'est__splitter': 'random'},\n",
       " {'est__bootstrap': True,\n",
       "  'est__class_weight': 'balanced_subsample',\n",
       "  'est__criterion': 'entropy',\n",
       "  'est__max_depth': 7},\n",
       " {'est__activation': 'identity',\n",
       "  'est__learning_rate': 'constant',\n",
       "  'est__solver': 'lbfgs'},\n",
       " {'est__algorithm': 'SAMME.R'},\n",
       " {'est__store_covariance': True}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est',\n",
       "                  KNeighborsClassifier(n_neighbors=11, weights='distance'))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est', SVC(C=1, kernel='poly', random_state=42))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est',\n",
       "                  GaussianProcessClassifier(kernel=1**2 * RBF(length_scale=1),\n",
       "                                            n_restarts_optimizer=1,\n",
       "                                            random_state=42))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est',\n",
       "                  DecisionTreeClassifier(max_depth=10, random_state=42,\n",
       "                                         splitter='random'))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est',\n",
       "                  RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                         criterion='entropy', max_depth=7,\n",
       "                                         max_features=1, random_state=42))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est',\n",
       "                  MLPClassifier(activation='identity', alpha=1, max_iter=1000,\n",
       "                                random_state=42, solver='lbfgs'))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est', AdaBoostClassifier(random_state=42))]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('est', QuadraticDiscriminantAnalysis(store_covariance=True))])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7555308182670435,\n",
       " 0.7322884180113082,\n",
       " 0.7086026208820875,\n",
       " 0.7409504993718342,\n",
       " 0.7484759816823743,\n",
       " 0.7242560435674927,\n",
       " 0.7463696476954451,\n",
       " 0.7291603927392865]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
